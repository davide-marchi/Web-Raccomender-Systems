{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e29377",
   "metadata": {},
   "source": [
    "# Advanced Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5370dbb",
   "metadata": {},
   "source": [
    "Note: this lab has been tested with Python 3.10. We recommend using the same Python version if there are problems with libraries used in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2eb054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data generated in W6 Lab or the provided data splits (see Absalon, W7 Lab)\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_pickle(\"train_dataframe.pkl\")\n",
    "df_test = pd.read_pickle(\"test_dataframe.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee73231",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "For this exercise, you can use the Python library Scikit-Surprise. Please find the documentation here: https://surprise.readthedocs.io/en/stable/getting_started.html.\n",
    "\n",
    "Define an SVD model with user and item biases that uses Stochastic Gradient Descend (SGD) to estimate the low-rank matrix based on only observed ratings.\n",
    "\n",
    "Fit the model on the full training set with $30$ latent factors and $100$ epochs. Keep Scikit-Surprise's default setting for all other parameters, but set the random state to $0$ for comparable results.\n",
    "\n",
    "Use the model to predict the unobserved ratings for the users in the training set. How many predictions are there and what is the average of all the predictions? Round the average of all predictions to the third decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f14ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  54746\n",
      "Average of predictions:  4.413\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset, SVD\n",
    "\n",
    "# Convert train data format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "training_matrix = Dataset.load_from_df(df_train[['reviewerID', 'asin', 'overall']], reader)\n",
    "\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "trainset = training_matrix.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD(n_factors=30, n_epochs=100)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(training_matrix.build_full_trainset())\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "print(\"Number of predictions: \", len(predictions))\n",
    "print(\"Average of predictions: \", round(np.mean([pred.est for pred in predictions]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d0c69",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "We will implement the Neural Matrix Factorization model using the Python library RecBole.\n",
    "Please find the documentation here: https://recbole.io/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1879e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: recbole in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (1.15.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (4.67.1)\n",
      "Requirement already satisfied: colorlog==4.7.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (4.7.2)\n",
      "Requirement already satisfied: colorama==0.4.4 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (0.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (1.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (6.0.2)\n",
      "Requirement already satisfied: tensorboard>=2.5.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (2.19.0)\n",
      "Requirement already satisfied: thop>=0.1.1.post2207130030 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (0.9.0)\n",
      "Requirement already satisfied: plotly>=4.0.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (6.0.0)\n",
      "Requirement already satisfied: texttable>=0.9.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from recbole) (1.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from pandas>=1.4.0->recbole) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from pandas>=1.4.0->recbole) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from pandas>=1.4.0->recbole) (2025.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from plotly>=4.0.0->recbole) (1.27.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from plotly>=4.0.0->recbole) (24.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from scikit-learn>=0.23.2->recbole) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from scikit-learn>=0.23.2->recbole) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (75.8.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from tensorboard>=2.5.0->recbole) (3.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from torch>=1.10.0->recbole) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->recbole) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "#Uncomment and run the following line if you need to install RecBole\n",
    "!pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a58eb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (2.42.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (8.1.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (3.17.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (24.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (5.29.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (1.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from ray) (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from click>=7.0->ray) (0.4.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from jsonschema->ray) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from jsonschema->ray) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from jsonschema->ray) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from jsonschema->ray) (0.23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from requests->ray) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from requests->ray) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from requests->ray) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from requests->ray) (2025.1.31)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\david\\anaconda3\\envs\\wrs\\lib\\site-packages (from referencing>=0.28.4->jsonschema->ray) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "#Uncomment and run the following line if you need to install ray. This is needed when calling run_recbole\n",
    "!pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b20d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from recbole.quick_start import run_recbole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49bbb1",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "Convert the dataset to the format which can be read by RecBole.\n",
    "\n",
    "More information regarding the input data format can be found here:\n",
    "https://recbole.io/docs/user_guide/usage/running_new_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcbae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are creating a dictionary that maps the column names in our dataset to the column names required by RecBole\n",
    "\n",
    "#Fill this dictionary with keys that are column names in our dataset that correspond to user_id, item_id, rating, and timestamp\n",
    "#Fill the values of the dictionary according to the given documentation\n",
    "\n",
    "col_name_dict = {\n",
    "                #write your code here.\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570e0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method converts a dataframe to a .inter file, and saves it in the folder \"data\" under the name 'file_name'\n",
    "def convert_df_to_inter(df:pd.DataFrame, col_name_dict:dict, file_name:str):\n",
    "    inter = df.copy()\n",
    "    selected_cols = col_name_dict.keys()\n",
    "    inter = inter[selected_cols]\n",
    "    #write your code to rename the columns in inter using col_name_dict\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    inter.to_csv(\"data/\"+file_name, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23315418",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2531659262.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    df_extra = #write your code here\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#create an extra, empty dataframe with the same column names in the keys of col_name_dict\n",
    "#we will use this as a dummy validation file\n",
    "df_extra = #write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_df_to_inter(df_train, col_name_dict, \"data.train.inter\")\n",
    "convert_df_to_inter(df_test, col_name_dict, \"data.test.inter\")\n",
    "convert_df_to_inter(df_extra, col_name_dict, \"data.extra.inter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe5a09",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "Train the Neural Matrix Factorization model on the whole training dataset for $100$ epochs.\n",
    "\n",
    "Evaluate the model on the test set, based on HR, MRR, Precision, MAP, and Recall at $k \\in \\{5, 10, 20\\}$ respectively and round the scores up to 3 decimal places (It is fine if you have different results in the third decimal point).\n",
    "Keep the rest of the default settings of RecBole the same.\n",
    "\n",
    "Note: RecBole's MAP normalises the recall base by $\\min\\{k,G\\}$, where $G$ is the recall base (see W7 lecture and homework solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a63a97",
   "metadata": {},
   "source": [
    "Note: A non exhaustive list of properties that can be set using the config_dict parameter of the run_recbole() method can be found here:\n",
    "https://github.com/RUCAIBox/RecBole/blob/master/recbole/properties/overall.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c443c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_recbole(\n",
    "                    model=#write your code here,\n",
    "                    dataset=\"data\",\n",
    "                    config_dict={\n",
    "                        \"data_path\":\"./\",\n",
    "                        \"benchmark_filename\": ['train', 'extra', 'test'],\n",
    "                        #complete the rest of the dictionary\n",
    "                    })\n",
    "\n",
    "#print the results here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb09d0",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Let's create a graph-based recommender system, defining neighbourhoods with random walks. Build a bipartite graph (i.e., edges only between users and items) where nodes are users and items; a **bidirectional** edge $(u,i)$ exists in the graph if user $u$ has rated item $i$ with a score $>3$. \n",
    "\n",
    "Implement the Page Rank algorithm to find the top-10 recommended items for user `ARARUVZ8RUF5T`. You can use the `pagerank` method from the library `networkx`. Assume a damping factor of $0.85$ and leave the rest of parameters by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f407c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "\n",
    "# Prepare the data\n",
    "def convert_data(df):\n",
    "    df_convert = #get the rows in the df where the rating is >3\n",
    "    df_convert = df_convert[[\"asin\",\"reviewerID\"]]\n",
    "    df_convert_arr = df_convert.values\n",
    "    return df_convert_arr\n",
    "\n",
    "train_df = convert_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975926df",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Hyper Parameters '''\n",
    "def parameter_dict_from_vector(vector):\n",
    "    return {\n",
    "        \"W_USER_ITEM\" : vector[0],\n",
    "        \"W_USER_ITEM_BACK\" : vector[1]\n",
    "        }\n",
    "\n",
    "''' Building Graph '''\n",
    "class InteractionGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.MultiDiGraph()\n",
    "        \n",
    "    def add_nodes_from_edge_array(self, edge_array, type_1, type_2):\n",
    "        nodes = [(x[0], {'type': type_1}) for x in edge_array] \\\n",
    "        + [(x[1], {'type': type_2}) for x in edge_array]\n",
    "        self.graph.add_nodes_from(nodes)\n",
    "\n",
    "    def add_edges_from_array(self, array, weight_front=1.0, weight_back=1.0):\n",
    "        forward_edges = [(x[0], x[1], weight_front) for x in array]\n",
    "        back_edges = [(x[1], x[0], weight_back) for x in array]\n",
    "        self.graph.add_weighted_edges_from(forward_edges)\n",
    "        self.graph.add_weighted_edges_from(back_edges)\n",
    "\n",
    "def build_graph(parameter_dictionary, user_item_array):\n",
    "    multigraph = InteractionGraph()\n",
    "    multigraph.add_nodes_from_edge_array(user_item_array, 'item', 'user')\n",
    "    multigraph.add_edges_from_array(user_item_array, \n",
    "                                    parameter_dictionary[\"W_USER_ITEM\"], \n",
    "                                    parameter_dictionary[\"W_USER_ITEM_BACK\"])\n",
    "    return multigraph\n",
    "\n",
    "class RecommendationEngine:\n",
    "    def __init__(self, multigraph, damping_factor = 0.3):\n",
    "        self.graph = nx.DiGraph()\n",
    "        for u,v,d in multigraph.graph.edges(data=True):\n",
    "            w = d['weight']\n",
    "            if self.graph.has_edge(u,v):\n",
    "                self.graph[u][v]['weight'] += w\n",
    "            else:\n",
    "                self.graph.add_edge(u,v,weight=w)\n",
    "        self.nodes = list(self.graph.nodes)\n",
    "        self.damping_factor = damping_factor\n",
    "        \n",
    "        #this part keeps track of items that have been rated by each user in the training set\n",
    "        self.user_item_dict = {}\n",
    "        for n in multigraph.graph.nodes.data():\n",
    "            if n[1]['type'] == 'user':\n",
    "                 self.user_item_dict[n[0]] = set()\n",
    "        for e in multigraph.graph.edges:\n",
    "            if e[0] in self.user_item_dict:\n",
    "                 self.user_item_dict[e[0]].add(e[1])\n",
    "\n",
    "    def generate_pr(self, damping_factor):\n",
    "        pr = #use the pagerank method here\n",
    "        pr_sorted = dict(\n",
    "            #sort pr by descending probability values\n",
    "            )\n",
    "        pr_list = [(k, v) for k, v in pr_sorted.items()]\n",
    "        return pr_list\n",
    "    \n",
    "    def generate_recommendations(self, user):\n",
    "        pr_list = self.generate_pr(self.damping_factor)\n",
    "        result = #Given the user, remove items in their recommendation list that they have rated in the training set\n",
    "        #hint: you can use user_item_dict for this\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcc5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_factor = #fill this\n",
    "\n",
    "# Build the graph\n",
    "graph = build_graph(parameter_dict_from_vector(np.ones(2)), train_df)\n",
    "# Build the recommender system with page rank\n",
    "recommender = RecommendationEngine(graph, damping_factor)\n",
    "\n",
    "# Get top-K recommendations for the given user \n",
    "user_id = \"ARARUVZ8RUF5T\"\n",
    "K = 10\n",
    "\n",
    "# write your code to get the top-K recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd76a50",
   "metadata": {},
   "source": [
    "Credits: the provided codes in Exercise 3 are modified from\n",
    "https://arxiv.org/pdf/2301.11009.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WRS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
